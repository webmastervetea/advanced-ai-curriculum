## 游눠 M치s All치 de los Datos: M칠todos para Inyectar Conocimiento de Sentido Com칰n en LLMs

Los Modelos de Lenguaje Grandes (LLMs), entrenados sobre vastas cantidades de texto, son expertos en sintaxis y sem치ntica. Sin embargo, a menudo fallan en tareas que requieren **razonamiento de sentido com칰n** (p. ej., saber que una cuerda se usa para tirar y no para empujar, o que un objeto grande no cabe en una caja peque침a). La inyecci칩n de conocimiento de sentido com칰n (*Common Sense Knowledge, CSK*) es crucial para aumentar la robustez, la precisi칩n y la interpretabilidad de los LLMs.

---

### 1. El Desaf칤o: El Conocimiento T치cito

El sentido com칰n es impl칤cito, incompleto y rara vez est치 escrito expl칤citamente en el texto de entrenamiento. Los LLMs pueden inferir muchas cosas, pero les cuesta manejar las lagunas causadas por la falta de un conocimiento fundamental y obvio.

### 2. Metodolog칤as de Inyecci칩n de Conocimiento

Existen tres enfoques principales para integrar el conocimiento de sentido com칰n en los LLMs: **Entrenamiento**, **Finetuning** y **Aumento durante la Inferencia**.

#### A. Inyecci칩n a trav칠s del Pre-entrenamiento (Training-Time Injection)

Este es el m칠todo m치s fundamental, donde el CSK se incorpora durante la fase inicial de pre-entrenamiento del LLM.

* **Fuentes de Conocimiento:** Se utilizan Grafos de Conocimiento de Sentido Com칰n (CSKGs) estructurados, como **ConceptNet** o **ATOMIC**, que contienen tripletas de conocimiento relacional (e.g., $(\text{persona}, \text{hace}, \text{comer})$).
* **T칠cnica:** Se dise침an **tareas auxiliares** durante el pre-entrenamiento. Adem치s de la tarea est치ndar de modelado de lenguaje (predecir la siguiente palabra), el modelo es simult치neamente penalizado o recompensado por predecir o completar hechos del CSKG.
    * **Ejemplo:** El modelo recibe una entidad y una relaci칩n (p. ej., "l치piz" y "usado para") y debe predecir la entidad final ("escribir").
* **Ventaja:** Integra el CSK directamente en la capa m치s profunda de la representaci칩n del modelo.

#### B. Finetuning Relacional y Adaptaci칩n (Finetuning Injection)

Una vez que el LLM est치 pre-entrenado, se puede afinar (*finetune*) para interiorizar el CSK mediante tareas espec칤ficas.

* **Finetuning Basado en Tareas (Downstream Tasks):**
    * Se afina el LLM con *datasets* dise침ados espec칤ficamente para el razonamiento de sentido com칰n, como **CommonsenseQA** o **Winogrande**.
    * Estas tareas fuerzan al modelo a utilizar el CSK para resolver ambigu팯edades o responder preguntas de opci칩n m칰ltiple.
* **Finetuning Basado en Estructura (Relational Finetuning):**
    * Similar a la inyecci칩n, pero solo en la fase de finetuning. Se utiliza una t칠cnica llamada **"Modelos de Lenguaje Gr치fico" (*Graph Language Models*)** donde se codifican las estructuras del CSKG y se fusionan con los *embeddings* de tokens del LLM.
    * **T칠cnica:** Se utiliza un mecanismo de atenci칩n que permite al LLM "mirar" la estructura relevante del CSKG mientras procesa la frase. 

#### C. Aumento durante la Inferencia (Inference-Time Augmentation)

Este es el enfoque m치s din치mico y no requiere modificar los pesos del LLM. El conocimiento se "recupera" (*retrieve*) y se presenta al modelo como parte del *prompt*.

##### i. Retrieval-Augmented Generation (RAG) con CSKGs
El RAG permite que el LLM acceda a una base de datos externa antes de generar la respuesta.

1.  **Consulta de CSK:** Cuando el LLM recibe una pregunta, un m칩dulo de recuperaci칩n consulta el CSKG (p. ej., ConceptNet) para obtener hechos relevantes.
2.  **Aumento del Prompt:** Los hechos recuperados (en formato de texto, p. ej., "Una persona toma un paraguas cuando llueve") se a침aden al *prompt* de entrada.
3.  **Generaci칩n de Respuesta:** El LLM genera la respuesta bas치ndose en el *prompt* original **m치s** el conocimiento de sentido com칰n expl칤cito inyectado.

##### ii. Chain-of-Thought (CoT) y Prompting
Aunque no es una "inyecci칩n" en el sentido estricto, las t칠cnicas de *prompting* avanzado gu칤an al modelo para que **externalice** su razonamiento.
* Al pedir al modelo que piense paso a paso ("Let's think step by step"), se le anima a activar el CSK que ha aprendido impl칤citamente, mejorando la coherencia l칩gica.

---

### 3. Impacto y Beneficios de la Inyecci칩n de CSK

| Beneficio | Descripci칩n | Ejemplo de Mejora |
| :--- | :--- | :--- |
| **Robustez** | Reduce las *alucinaciones* del modelo al anclar las respuestas a hechos verificables de sentido com칰n. | El modelo no sugerir치 que se puede viajar de Pamplona a Madrid en 5 minutos. |
| **Interpretabilidad** | Permite rastrear la fuente de la respuesta a un hecho espec칤fico del CSKG, mejorando la confianza. | Se puede mostrar qu칠 hecho de ConceptNet se utiliz칩 para el razonamiento. |
| **Razonamiento Causal** | Mejora la comprensi칩n de causa y efecto, un componente clave del sentido com칰n. | Distinguir entre "La lluvia caus칩 el barro" y "El barro caus칩 la lluvia". |
| **Transferencia (*Zero-Shot*)** | El modelo aplica el conocimiento aprendido en un dominio a una tarea completamente nueva, ya que el CSK es universal. |

---

### 4. Desaf칤os a Futuro

A pesar de los avances, la inyecci칩n de CSK enfrenta retos:

1.  **Integraci칩n Sem치ntica:** C칩mo fusionar de manera 칩ptima los *embeddings* textuales con los *embeddings* gr치ficos (estructurales) sin que el ruido de uno corrompa al otro.
2.  **Escalabilidad:** Los CSKG son finitos. El sentido com칰n humano es vasto y en constante evoluci칩n.
3.  **Adquisici칩n de Conocimiento:** Desarrollar m칠todos autom치ticos para extraer CSK de texto no estructurado con mayor fiabilidad que los m칠todos de pre-entrenamiento pasivos.

La inyecci칩n de conocimiento de sentido com칰n representa la transici칩n de los LLMs de meros predictores de palabras a **agentes de razonamiento**. Es la clave para desbloquear aplicaciones de IA m치s seguras, fiables e inteligentes.

---

Continua: [[23.1.1](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/23-1-1.md)] 

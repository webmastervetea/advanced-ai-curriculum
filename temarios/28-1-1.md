
##  El Enfoque Causal: Explicaciones del "Por Qu茅" en la Inteligencia Artificial

La Explicabilidad de la IA (XAI) tradicional a menudo se limita a la **correlaci贸n**: identificar qu茅 *caracter铆sticas* estuvieron activas durante una predicci贸n (ej., "el p铆xel rojo fue importante"). Sin embargo, para construir sistemas confiables y equitativos, necesitamos explicaciones **causales**: demostrar que una caracter铆stica espec铆fica *caus贸* o *influy贸 directamente* en la predicci贸n, y no solo que estuvo presente.

La explicaci贸n causal responde a la pregunta crucial: "**驴Qu茅 pasar铆a si...?**" (Contrafactualidad).

---

### 1. El Salto de la Correlaci贸n a la Causalidad

| Explicaci贸n Correlacional | Explicaci贸n Causal (Contrafactual) |
| :--- | :--- |
| **"El modelo predijo un perro porque el p铆xel asociado al pelo casta帽o tuvo un alto gradiente."** | **"Si el pelo casta帽o en la imagen hubiera sido gris, la predicci贸n hubiera cambiado de 'perro' a 'lobo'."** |
| Se centra en la influencia local del dato. | Se centra en el impacto de la **modificaci贸n** del dato. |
| No garantiza la generalizaci贸n. | Implica una relaci贸n de influencia directa. |

### 2. T茅cnicas Basadas en la Perturbaci贸n y la Contrafactualidad

Los m茅todos de explicabilidad causal se basan en cambiar intencionadamente la entrada para medir el efecto en la salida.

#### A. Explicaciones Contrafactuales (*Counterfactual Explanations*)

* **Principio:** Buscar la entrada m铆nima modificada que cambia la predicci贸n del modelo a una clase diferente (o una salida deseada).
* **Mecanismo:** Dado un punto de datos $x$ con predicci贸n $y$, se busca un nuevo punto $x'$ tal que la predicci贸n del modelo $f(x')$ sea la clase objetivo $y'$, y la distancia entre $x$ y $x'$ sea m铆nima.
    $$x^* = \text{argmin}_{x'} \text{dist}(x, x') \quad \text{sujeto a } f(x') = y'$$
* **Resultado:** La diferencia $\Delta x = x' - x$ es la **causa** de la diferencia en la predicci贸n. Por ejemplo, si se le niega un pr茅stamo a un usuario, la explicaci贸n contrafactual podr铆a ser: "Si hubieras tenido una antig眉edad laboral de 5 a帽os en lugar de 2, el pr茅stamo habr铆a sido aprobado."

#### B. Valores SHAP (*SHapley Additive exPlanations*)

SHAP, aunque basado en la teor铆a de juegos (valores Shapley), proporciona una visi贸n m谩s cercana a la causalidad que otras m茅tricas de importancia de caracter铆sticas.

* **Principio:** Atribuir la diferencia entre la predicci贸n de la instancia y la predicci贸n promedio (o base) a cada caracter铆stica, considerando todas las posibles combinaciones de caracter铆sticas.
* **Mecanismo:** SHAP mide la contribuci贸n marginal promedio de una caracter铆stica al cambiar la predicci贸n a medida que se "a帽ade" esa caracter铆stica a un subconjunto.
* **Visi贸n Causal:** Al considerar c贸mo la presencia de una caracter铆stica *cambia* la predicci贸n, SHAP proporciona una medida de la influencia causal a nivel local (para esa instancia espec铆fica).

---

### 3. T茅cnicas de Intervenci贸n Causal y Gr谩ficos

Estos m茅todos intentan modelar las relaciones causales reales entre las caracter铆sticas, independientemente del modelo de caja negra.

#### A. Mapas de Atribuci贸n Causal (*Causal Attribution Maps*)

Comunes en visi贸n por computadora, estos mapas van m谩s all谩 de la simple activaci贸n de p铆xeles:

1.  **Intervenci贸n:** Se perturban sistem谩ticamente regiones de la imagen o fragmentos de texto.
2.  **Medici贸n:** Se mide c贸mo la perturbaci贸n en una regi贸n A afecta la activaci贸n o el gradiente en una regi贸n B del mapa de caracter铆sticas.
3.  **Resultado:** Esto ayuda a determinar si la relaci贸n que el modelo est谩 aprendiendo es causalmente v谩lida. Por ejemplo, en lugar de solo resaltar la cara de un perro, resalta la *ausencia* de cola o las orejas, mostrando que esas caracter铆sticas espec铆ficas *causaron* la predicci贸n de una raza espec铆fica.

#### B. Inferencia Causal (Do-Calculus)

Para casos donde se sospecha de variables de confusi贸n, la inferencia causal proporciona un marco te贸rico riguroso.

* **Concepto:** Utilizar el c谩lculo *Do-Calculus* de Judea Pearl para distinguir la correlaci贸n de la causalidad.
* **Mecanismo:** Se construye un **Grafo Causal** que representa las relaciones de causa y efecto esperadas entre las variables del problema. La explicabilidad causal se basa en determinar si la predicci贸n del modelo es consistente con las intervenciones definidas por el grafo.
* **Aplicaci贸n en XAI:** Permite probar si el modelo est谩 utilizando un atajo (*shortcut*) correlacional (ej., "el fondo del hospital causa la predicci贸n de enfermedad") en lugar del factor causal real (la imagen del tumor). La explicaci贸n causal entonces se centra en el nodo del grafo que realmente influye.

---

### 4. Importancia en Seguridad y Equidad

La exigencia de causalidad en la XAI es crucial para la 茅tica y la fiabilidad:

* **Eliminaci贸n de Sesgos:** Una explicaci贸n causal puede revelar si una decisi贸n se bas贸 en una variable sesgada (ej., c贸digo postal) en lugar de una variable causal leg铆tima (ej., historial crediticio). Al identificar la causa real, se puede corregir la pol铆tica del modelo.
* **Confianza Regulatoria:** En sectores regulados (finanzas, medicina), el "por qu茅" debe ser legalmente defendible. La causalidad contrafactual proporciona las condiciones m铆nimas necesarias para cambiar la decisi贸n, lo que es esencial para el cumplimiento.
* **Robustez:** Una explicaci贸n causal robusta sugiere que el modelo no est谩 utilizando atajos o correlaciones espurias que podr铆an fallar catastr贸ficamente en el mundo real.

---

### Conclusi贸n

La transici贸n de la explicabilidad de la correlaci贸n a la causalidad es el siguiente gran paso para la XAI. Al utilizar t茅cnicas como las explicaciones contrafactuales, los valores SHAP y la inferencia causal basada en grafos, los desarrolladores pueden generar explicaciones que demuestran la influencia directa de las caracter铆sticas, lo que lleva a sistemas de IA m谩s justos, confiables y verdaderamente inteligibles para sus usuarios.


Continua: [[28.2.1](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/28-2-1.md)] 



## üîÑ Aprendizaje por Transferencia Profunda con Adaptaci√≥n: Reutilizando el Conocimiento

El **Aprendizaje por Transferencia** se basa en la idea de que un modelo entrenado en un gran *dataset* de origen (Source Domain, $\mathcal{D}_S$) ha aprendido caracter√≠sticas generales y √∫tiles (bordes, texturas, sintaxis, gram√°tica) que pueden ser rehusadas y transferidas a una nueva tarea objetivo (Target Domain, $\mathcal{D}_T$).

### 1. Modelos Fundamentales de Transferencia

#### A. Ajuste Fino (*Fine-Tuning*)
Es el m√©todo m√°s com√∫n y se aplica a la mayor√≠a de los modelos (ej. ResNet para visi√≥n, BERT para lenguaje).

* **Mecanismo:**
    1.  Se inicializa el modelo con los **pesos pre-entrenados** de $\mathcal{D}_S$.
    2.  Se **reemplaza la capa de salida** para que coincida con el n√∫mero de clases de $\mathcal{D}_T$.
    3.  Se entrena el modelo completo (o solo las √∫ltimas capas) usando los peque√±os datos de $\mathcal{D}_T$ con una tasa de aprendizaje muy baja para no "olvidar" el conocimiento original.
* **Principio:** Asume que $\mathcal{D}_S$ y $\mathcal{D}_T$ son relativamente similares (ej., clasificar perros en un *dataset* diferente de perros).

#### B. Congelamiento de Capas (*Feature Extraction*)
Para *datasets* objetivo muy peque√±os, se congela la mayor parte del modelo pre-entrenado.

* **Mecanismo:** Se congelan todas las capas convolucionales o de *Transformer* (dejando sus pesos fijos). Solo la nueva capa de clasificaci√≥n final es entrenada con los datos de $\mathcal{D}_T$.
* **Principio:** El modelo pre-entrenado se utiliza puramente como un **extractor de caracter√≠sticas** robusto.

### 2. T√©cnicas de Adaptaci√≥n de Dominio y Generalizaci√≥n

Cuando $\mathcal{D}_S$ y $\mathcal{D}_T$ son significativamente diferentes (ej., entrenado en im√°genes reales y aplicado a im√°genes de dibujos animados, o entrenado en ingl√©s y aplicado a un dialecto espec√≠fico), se requiere una adaptaci√≥n m√°s sofisticada.

#### A. Adaptaci√≥n de Bajo Rango (LoRA)
Esta es la t√©cnica de adaptaci√≥n m√°s eficiente en t√©rminos de memoria y c√≥mputo, especialmente para LLMs.

* **Mecanismo:** En lugar de ajustar los miles de millones de par√°metros originales del modelo ($\mathbf{W}$), LoRA congela $\mathbf{W}$ y aprende solo un peque√±o par de matrices de rango bajo ($\mathbf{A}$ y $\mathbf{B}$).
    $$\mathbf{W}_{\text{adaptada}} = \mathbf{W} + \mathbf{A}\mathbf{B}^T$$
* **Ventaja:** Requiere un almacenamiento m√≠nimo para guardar los "adaptadores" ($\mathbf{A}$ y $\mathbf{B}$), permitiendo la **personalizaci√≥n r√°pida** a m√∫ltiples tareas o dominios sin la necesidad de copiar el modelo base completo.

#### B. Generalizaci√≥n de Dominio (Domain Generalization, DG)

DG busca entrenar un modelo que funcione bien en un dominio objetivo **invisible** (nunca visto). Se entrena en m√∫ltiples dominios de origen (Source Domains) con la esperanza de que el conocimiento sea verdaderamente general.

* **T√©cnica Clave: Invarianza de Caracter√≠sticas:** La red es forzada a aprender caracter√≠sticas que son **invariantes** a los cambios de dominio.
    1.  El modelo aprende a clasificar correctamente.
    2.  Se a√±ade un **M√≥dulo Adversario** que intenta predecir de qu√© **dominio** proviene la caracter√≠stica.
    3.  El clasificador es penalizado si el m√≥dulo Adversario tiene √©xito.
    4.  **Resultado:** El *embedding* de caracter√≠sticas generado por el clasificador se vuelve "ciego" a la identidad del dominio, solo conteniendo informaci√≥n relevante para la tarea.



### 3. T√©cnicas de Distancia y Alineaci√≥n

Para tareas donde $\mathcal{D}_S$ y $\mathcal{D}_T$ tienen diferentes distribuciones de datos (por ejemplo, el brillo de las im√°genes difiere), se utiliza el *Metric Learning* para alinear sus *embeddings*.

* **Alineaci√≥n de Distribuci√≥n (MMD - Maximum Mean Discrepancy):** Se a√±ade una funci√≥n de p√©rdida que mide la distancia (o discrepancia) entre la distribuci√≥n de *embeddings* del dominio de origen ($\mathcal{D}_S$) y el dominio objetivo ($\mathcal{D}_T$).
* **Mecanismo:** La red se entrena para minimizar la p√©rdida de clasificaci√≥n en $\mathcal{D}_S$ y, al mismo tiempo, minimizar el $\text{MMD}$ entre $\mathcal{D}_S$ y $\mathcal{D}_T$. Esto fuerza a los *embeddings* del dominio objetivo a alinearse con los *embeddings* del dominio de origen, incluso si no tienen etiquetas.

### 4. Conclusi√≥n

El **Aprendizaje por Transferencia Profunda con Adaptaci√≥n** es vital para la aplicaci√≥n pr√°ctica de la IA. Mediante la reutilizaci√≥n eficiente de modelos pre-entrenados y el uso de t√©cnicas avanzadas como **LoRA** (para eficiencia) y la **Generalizaci√≥n de Dominio Adversaria** (para la robustez en nuevos dominios), la IA puede adaptarse r√°pidamente a nuevas tareas con un m√≠nimo de datos etiquetados, acelerando dr√°sticamente el despliegue en nuevos contextos.

---

Continua: [[45.1](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/45-1.md)] 

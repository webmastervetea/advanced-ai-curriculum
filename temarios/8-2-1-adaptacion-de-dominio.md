#  Adaptaci贸n de Dominio (*Domain Adaptation*): Superando el Salto de Distribuci贸n

La **Adaptaci贸n de Dominio (*Domain Adaptation*)** es una rama del **Aprendizaje por Transferencia (*Transfer Learning*)** que se enfoca en resolver un problema fundamental en el *Machine Learning* aplicado: la **brecha de dominio**.

Esta brecha ocurre cuando un modelo entrenado en un conjunto de datos (el **Dominio Fuente**) tiene un rendimiento significativamente pobre cuando se aplica a un conjunto de datos diferente, pero relacionado (el **Dominio Objetivo**), debido a una disparidad en las distribuciones estad铆sticas de los datos.

## 1. El Problema de la Brecha de Dominio

En el *Machine Learning* tradicional, se asume que los datos de entrenamiento y los datos de prueba provienen de la **misma distribuci贸n** de probabilidad. Sin embargo, en la pr谩ctica, esta suposici贸n a menudo se rompe:

* **Dominio Fuente ($D_S$):** El conjunto de datos grande y **etiquetado** donde el modelo es entrenado (ej. im谩genes limpias de un cat谩logo profesional).
* **Dominio Objetivo ($D_T$):** El conjunto de datos de producci贸n **no etiquetado** o con pocas etiquetas (ej. im谩genes borrosas o con poca luz de una c谩mara de vigilancia real).

Aunque la **tarea** a realizar es la misma (ej. clasificaci贸n de objetos), la **distribuci贸n de los datos** ($P_S(\mathbf{X}) \neq P_T(\mathbf{X})$) ha cambiado. El objetivo de la Adaptaci贸n de Dominio es utilizar la informaci贸n del Dominio Fuente para mejorar el rendimiento en el Dominio Objetivo con una m铆nima o nula intervenci贸n humana. 

## 2. Clasificaciones Clave de la Adaptaci贸n de Dominio

La adaptaci贸n se clasifica seg煤n la disponibilidad de etiquetas en el Dominio Objetivo:

| Clasificaci贸n | Etiquetas en $D_T$ | Descripci贸n | Aplicaci贸n T铆pica |
| :--- | :--- | :--- | :--- |
| **Adaptaci贸n Supervisada** | Muchas | El Dominio Objetivo tiene suficientes datos etiquetados para un ajuste fino (*fine-tuning*) est谩ndar. | Requiere el mayor costo de etiquetado. |
| **Adaptaci贸n Semi-Supervisada** | Pocas | El Dominio Objetivo tiene una peque帽a cantidad de datos etiquetados que se usan junto con muchos datos sin etiquetar. | Situaci贸n intermedia, m谩s realista. |
| **Adaptaci贸n No Supervisada (UDA)** | Ninguna | El Dominio Objetivo **no tiene etiquetas**. Toda la adaptaci贸n debe basarse en la alineaci贸n de caracter铆sticas. | M谩s desafiante y de mayor inter茅s en la investigaci贸n actual. |

---

## 3. T茅cnicas de Adaptaci贸n de Dominio No Supervisada (UDA)

La UDA es el subcampo m谩s activo, ya que aborda el problema de la falta de etiquetas. Las t茅cnicas se centran en alinear el espacio de caracter铆sticas de los dos dominios.

### A. M茅todos Basados en Discrepancia

Estos m茅todos intentan minimizar una m茅trica que cuantifica la distancia entre las distribuciones de caracter铆sticas de los dos dominios en el espacio de *embedding*.

* **MMD (Maximum Mean Discrepancy):** Utiliza funciones *kernel* para medir la distancia entre las medias de las caracter铆sticas de $D_S$ y $D_T$ en un espacio de Hilbert de caracter铆sticas. El modelo se entrena para minimizar la p茅rdida de clasificaci贸n en $D_S$ y simult谩neamente minimizar la distancia MMD entre $D_S$ y $D_T$.

### B. M茅todos Basados en Aprendizaje Adversario (DAAN)

Esta es la t茅cnica m谩s popular y se inspira en las **Redes Generativas Adversarias (GANs)**.

1.  **Extractor de Caracter铆sticas ($G_f$):** Una red neuronal (el generador) que mapea la entrada al espacio de *embedding*.
2.  **Clasificador de Dominio ($D_d$):** Una red discriminadora que intenta predecir de qu茅 **dominio** (Fuente o Objetivo) proviene una caracter铆stica dada.
3.  **Entrenamiento:**
    * El **Clasificador de Dominio** ($D_d$) se entrena para ser lo m谩s preciso posible.
    * El **Extractor de Caracter铆sticas** ($G_f$) se entrena para **enga帽ar** al clasificador de dominio, generando representaciones que son indistinguibles entre los dos dominios.

Al maximizar la p茅rdida de $D_d$ (su error), el extractor $G_f$ produce **representaciones invariantes al dominio**. El clasificador final se entrena 煤nicamente en las etiquetas de $D_S$ utilizando estas representaciones invariantes.

* **Ejemplos:** **DANN** (*Domain-Adversarial Neural Network*) es el ejemplo protot铆pico.

### C. M茅todos Basados en Pseudo-Etiquetas

Estos m茅todos utilizan el modelo entrenado en $D_S$ para generar etiquetas para el Dominio Objetivo, que luego se utilizan para auto-entrenar el modelo.

1.  **Predicci贸n:** El modelo entrenado en $D_S$ genera predicciones para $D_T$.
2.  **Filtrado:** Solo las predicciones con **alta confianza** (pseudo-etiquetas) se mantienen.
3.  **Ajuste Fino:** El modelo se ajusta utilizando la p茅rdida de clasificaci贸n en el Dominio Objetivo con estas pseudo-etiquetas de alta confianza.
4.  **Iteraci贸n:** El proceso se repite, mejorando la calidad de las pseudo-etiquetas en cada iteraci贸n.

---

## 4. Aplicaciones Cr铆ticas de la Adaptaci贸n de Dominio

La Adaptaci贸n de Dominio es indispensable en escenarios donde la recolecci贸n de datos etiquetados en el entorno operativo es costosa, inviable o peligrosa:

* **Visi贸n por Computadora:**
    * **Simulaci贸n a Realidad (*Sim-to-Real*):** Adaptar modelos entrenados en entornos de simulaci贸n (coches aut贸nomos, rob贸tica) a datos del mundo real.
    * **Cambios de Estilo:** Adaptar un clasificador entrenado en fotos de d铆a a fotos de noche, o de fotos a dibujos/bocetos.
* **Procesamiento de Lenguaje Natural (NLP):**
    * **Traducci贸n entre Variantes:** Adaptar un modelo entrenado en ingl茅s brit谩nico a ingl茅s americano, o de espa帽ol de Espa帽a a variantes latinoamericanas.
    * **Cambios de G茅nero:** Adaptar un modelo entrenado en noticias formales a texto de redes sociales o *blogs*.
* **Diagn贸stico M茅dico:** Adaptar un modelo entrenado en un conjunto de datos de im谩genes de un hospital a las im谩genes de otro hospital, donde el equipo (y por lo tanto la distribuci贸n de p铆xeles) es diferente.

## 5. El Futuro de la Adaptaci贸n

Las t茅cnicas modernas se est谩n moviendo hacia la **Adaptaci贸n de Dominio Generalizado (*Generalized Domain Adaptation*, GDA)**, donde no solo se asume que las distribuciones son diferentes, sino que el modelo debe funcionar bien tanto en el Dominio Fuente como en el Dominio Objetivo despu茅s de la adaptaci贸n. El objetivo final es la creaci贸n de modelos que sean robustos ante cualquier cambio de distribuci贸n no anticipado.


---

Continua: [[8-2-2](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/8-2-2-few-shot-y-zero-shot.md)] 

#  Modelos Gr谩ficos Causales (DAGs) y el C谩lculo Do: Formalizando la Causa y el Efecto

La **Inferencia Causal** es la rama de la estad铆stica que busca determinar las relaciones de causa y efecto, respondiendo a la pregunta fundamental: "驴Qu茅 pasar铆a si...?" A diferencia de la inferencia predictiva (que solo busca correlaciones), la causalidad requiere herramientas que permitan simular una **intervenci贸n** o una **manipulaci贸n**.

El marco formal para esto se basa en los **Gr谩ficos Ac铆clicos Dirigidos Causales (DAGs)** y el **C谩lculo Do ($\text{do}(\cdot)$)**.

## 1. Modelos Gr谩ficos Causales (DAGs)

Un **Gr谩fico Ac铆clico Dirigido (DAG)** es una representaci贸n visual y matem谩tica de las relaciones causales en un sistema.

### A. Elementos del DAG

* **Nodos (Variables):** Representan variables aleatorias en el sistema (ej. un tratamiento, una enfermedad, un ingreso).
* **Arcos Dirigidos (Flechas):** Representan una **relaci贸n causal directa**. Si existe una flecha de $X$ a $Y$ ($X \to Y$), esto significa que **$X$ es una causa directa de $Y$**. La aciclicidad significa que no puede haber bucles causales (una variable no puede causarse a s铆 misma).
* **Estructura Causal:** El DAG codifica supuestos cruciales sobre la independencia condicional en el sistema, espec铆ficamente, la ausencia de una flecha entre $X$ y $Y$ implica que $Y$ no es una causa directa de $X$ (o viceversa).

### B. Caminos y Bloqueo de Informaci贸n (d-Separaci贸n)

La informaci贸n fluye a lo largo de los caminos en el DAG, y ciertas variables pueden bloquear o permitir este flujo, un concepto llamado **d-Separaci贸n** (*d-Separation*). Los tres patrones causales b谩sicos que definen el flujo de informaci贸n son:

| Patr贸n | Representaci贸n | Nombre | Flujo de Informaci贸n |
| :--- | :--- | :--- | :--- |
| **Cadena** | $X \to M \to Y$ | Mediador | La informaci贸n fluye de $X$ a $Y$ a menos que $M$ sea observado. |
| **Bifurcaci贸n** | $X \leftarrow C \to Y$ | Confusor (*Confounder*) | El efecto de $C$ es espurio. La correlaci贸n $X-Y$ se bloquea al **condicionar** en $C$. |
| **Colisionador** | $X \to K \leftarrow Y$ | Colisionador (*Collider*) | La informaci贸n **no fluye** entre $X$ y $Y$. La correlaci贸n se **crea** al **condicionar** en $K$. |

El **Confusor** ($C$) es el principal desaf铆o de la inferencia observacional. La correlaci贸n observada entre $X$ y $Y$ no es causal, sino que es causada por $C$. Para obtener la relaci贸n causal real, debemos **ajustar** o **controlar** por $C$.

## 2. El C谩lculo Do ($\text{do}(\cdot)$) y la Intervenci贸n

La diferencia crucial entre la **observaci贸n** y la **intervenci贸n** se formaliza mediante la introducci贸n del **operador do**.

### A. Observaci贸n vs. Intervenci贸n

1.  **Observaci贸n ($P(Y | X=x)$):** La probabilidad de que $Y$ sea $y$ **dado que hemos observado** que $X$ tom贸 el valor $x$. Esto mide la **correlaci贸n**.
2.  **Intervenci贸n ($P(Y | \text{do}(X=x))$):** La probabilidad de que $Y$ sea $y$ **dado que hemos forzado** o **intervenido** en el sistema para fijar $X$ al valor $x$. Esto mide la **causalidad**.



### B. El Mecanismo de Intervenci贸n (Gr谩fico Mutilado)

El operador $\text{do}(X=x)$ se modela en el DAG mediante una **"cirug铆a" o mutilaci贸n** del gr谩fico:

* **Paso 1:** Se elimina cualquier flecha dirigida que **entre** en el nodo $X$. Esto refleja que el valor de $X$ ya no est谩 determinado por sus causas originales; ha sido fijado externamente por el experimentador.
* **Paso 2:** El nodo $X$ se fija al valor $x$.
* **Paso 3:** Se calcula la probabilidad de $Y$ en este **gr谩fico mutilado**.

## 3. El Ajuste del Respaldo (*Backdoor Adjustment*)

El objetivo principal es encontrar la relaci贸n causal *a partir de datos observacionales*, es decir, encontrar una f贸rmula que permita calcular $P(Y | \text{do}(X=x))$ utilizando solo probabilidades observacionales $P(\cdot | \cdot)$.

La herramienta m谩s famosa para esto es el **Criterio del Camino de Respaldo (*Backdoor Criterion*)**.

### A. El Criterio del Camino de Respaldo

Para calcular el efecto causal de $X$ en $Y$, necesitamos encontrar un conjunto de variables de control $\mathbf{Z}$ (el **conjunto de ajuste**) que cumpla dos condiciones:

1.  **Bloqueo de Respaldo:** El conjunto $\mathbf{Z}$ debe bloquear todos los **caminos de respaldo** entre $X$ y $Y$ (caminos que van de $X$ a $Y$ con una flecha saliendo de $X$).
2.  **No Creaci贸n de Sesgo:** $\mathbf{Z}$ no debe ser un descendiente de $X$.

Si se encuentra dicho conjunto $\mathbf{Z}$, el efecto causal se puede calcular mediante la **F贸rmula de Ajuste del Respaldo**:

$$P(Y| \text{do}(X=x)) = \sum_{\mathbf{z}} P(Y|X=x, \mathbf{Z}=\mathbf{z}) P(\mathbf{Z}=\mathbf{z})$$

* Esta f贸rmula descompone el efecto causal en una suma ponderada de las probabilidades condicionales, ajustando por el efecto del confusor $\mathbf{Z}$.

## 4. Legado e Impacto

La formalizaci贸n de la causalidad a trav茅s de DAGs y el C谩lculo Do, principalmente por Judea Pearl, ha tenido un impacto profundo:

* **IA Explicable:** Permite a los modelos no solo predecir, sino tambi茅n razonar sobre los mecanismos de decisi贸n.
* **Ciencias Sociales y Econom铆a:** Permite a los investigadores identificar qu茅 variables deben ser controladas en un an谩lisis de regresi贸n para eliminar el sesgo de las variables confusoras.
* **ML Causal:** Las bibliotecas modernas (como DoWhy o CausalPy) implementan estos principios, permitiendo a los ingenieros de datos y cient铆ficos de ML realizar an谩lisis causales rigurosos a partir de datos observacionales complejos.

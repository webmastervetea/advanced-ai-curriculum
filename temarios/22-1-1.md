##  El Arte de la Representaci贸n: T茅cnicas de Embedding para Grafos de Conocimiento

Los **Grafos de Conocimiento (KG)** almacenan informaci贸n del mundo real como tripletas de la forma $(\text{entidad}_1, \text{relaci贸n}, \text{entidad}_2)$, por ejemplo, $(\text{Madrid}, \text{es\_capital\_de}, \text{Espa帽a})$. Para que los algoritmos de *Machine Learning* puedan procesar y razonar sobre esta estructura, necesitamos convertir entidades y relaciones discretas en vectores num茅ricos continuos: los **Embeddings**.

---

### 1. El Fundamento: 驴Qu茅 son los Embeddings de Grafos?

Un *embedding* es una representaci贸n vectorial de baja dimensionalidad que captura las propiedades y las relaciones de un nodo o una arista en un espacio vectorial.

* **Entidades (Nodos):** Se representan como vectores $e \in \mathbb{R}^k$.
* **Relaciones (Aristas):** Se representan como vectores $r \in \mathbb{R}^k$ (o matrices/tensores m谩s complejos).

El objetivo es que los *embeddings* se ajusten a una **funci贸n de puntuaci贸n (*scoring function*)** dise帽ada para que las tripletas verdaderas tengan una puntuaci贸n alta y las falsas, una puntuaci贸n baja.

>  **Principio Clave:** La distancia o la interacci贸n vectorial entre $e_1$ y $e_2$ debe reflejar la sem谩ntica de la relaci贸n $r$.

---

### 2. Modelos Basados en Distancia: TransE (Translational Embeddings)

**TransE** es uno de los modelos de *embedding* m谩s influyentes y conceptualmente sencillos, basado en la idea de que la **relaci贸n act煤a como un vector de traslaci贸n** entre la entidad principal y la entidad objetivo.

#### A. La Hip贸tesis Central

Para una tripleta verdadera $(\text{cabeza}, \text{relaci贸n}, \text{cola})$, el *embedding* de la entidad cabeza ($h$) m谩s el *embedding* de la relaci贸n ($r$) debe ser aproximadamente igual al *embedding* de la entidad cola ($t$).

$$\mathbf{h} + \mathbf{r} \approx \mathbf{t}$$



#### B. La Funci贸n de Puntuaci贸n (*Scoring Function*)

La puntuaci贸n se calcula midiendo la distancia (generalmente $L_1$ o $L_2$) entre el resultado de la traslaci贸n $(\mathbf{h} + \mathbf{r})$ y el vector de cola $\mathbf{t}$.

$$f_{r}(h, t) = ||\mathbf{h} + \mathbf{r} - \mathbf{t}||_{p}$$

* **Objetivo de Entrenamiento:** Minimizar la puntuaci贸n para las tripletas verdaderas y maximizarla para las tripletas falsas (generadas por corrupci贸n).

#### C. Limitaciones de TransE

TransE maneja muy bien las relaciones **uno a uno** (como "es\_capital\_de"). Sin embargo, tiene dificultades con:

* **Relaciones Uno a Muchos, Muchos a Uno y Muchos a Muchos:** Tiende a asignar *embeddings* id茅nticos a las entidades en el lado "muchos", perdiendo la capacidad discriminatoria.
* **Relaciones Sim茅tricas** (p. ej., "es\_colega\_de"): Si $\mathbf{h} + \mathbf{r} \approx \mathbf{t}$ y $\mathbf{t} + \mathbf{r} \approx \mathbf{h}$, entonces $\mathbf{r}$ debe ser aproximadamente cero, lo que no es sem谩nticamente 煤til.

---

### 3. Modelos Basados en la Interacci贸n Sem谩ntica: ComplEx

Para superar las limitaciones de TransE con la simetr铆a y las relaciones de cardinalidad compleja, surgieron modelos que utilizan espacios vectoriales m谩s ricos, como los **n煤meros complejos**. **ComplEx** (Complex Embeddings) es un modelo basado en la multiplicaci贸n bilineal.

#### A. El Espacio Vectorial Complejo

En ComplEx, los *embeddings* de entidades ($\mathbf{h}, \mathbf{t}$) y relaciones ($\mathbf{r}$) se definen en el espacio de n煤meros complejos $\mathbb{C}^k$.

$$\mathbf{h}, \mathbf{t}, \mathbf{r} \in \mathbb{C}^k$$

Un n煤mero complejo $z$ se define como $a + bi$, donde $a$ es la parte real ($\text{Re}(z)$) y $b$ es la parte imaginaria ($\text{Im}(z)$).

#### B. La Funci贸n de Puntuaci贸n (*Scoring Function*)

ComplEx utiliza un producto de triple tensor para modelar la interacci贸n, aprovechando la **conjugaci贸n compleja** para manejar la direccionalidad y la simetr铆a de las relaciones.

La puntuaci贸n se calcula como la parte real del producto de la entidad cabeza, la relaci贸n y el conjugado de la entidad cola.

$$f_{r}(h, t) = \text{Re} \left( \sum_{i=1}^k h_i \cdot r_i \cdot \overline{t}_i \right)$$

* Donde $\overline{t}$ es el conjugado complejo de $\mathbf{t}$.

#### C. Ventajas Clave de ComplEx

1.  **Manejo de Asimetr铆a y Simetr铆a:** La multiplicaci贸n por el conjugado permite que el modelo distinga f谩cilmente entre $(h, r, t)$ y $(t, r, h)$ (asimetr铆a), mientras que las relaciones sim茅tricas se manejan de forma natural sin colapsar el vector $r$ a cero.
2.  **Expresividad:** Al operar en el espacio complejo, el modelo tiene el doble de par谩metros por dimensi贸n que los modelos reales, lo que aumenta su capacidad de modelar patrones sutiles. ComplEx es, en esencia, un modelo de factorizaci贸n tensorial **Canchy**.

---

### 4. Metodolog铆a de Entrenamiento Com煤n

Ambos modelos, y la mayor铆a de los modelos de *embedding* de KG, se entrenan utilizando el mismo paradigma:

1.  **Generaci贸n de Negativos (*Negative Sampling*):** Para cada tripleta verdadera $(\mathbf{h}, \mathbf{r}, \mathbf{t})$, se generan tripletas falsas (negativas) sustituyendo aleatoriamente la cabeza o la cola (p. ej., $(\mathbf{h'}, \mathbf{r}, \mathbf{t})$ o $(\mathbf{h}, \mathbf{r}, \mathbf{t'})$).
2.  **Funci贸n de P茅rdida Basada en M谩rgenes (*Margin-based Loss*):** Se utiliza una funci贸n de p茅rdida que busca mantener una distancia (margen, $\gamma$) entre la puntuaci贸n de las tripletas verdaderas y la puntuaci贸n de las falsas.

$$\mathcal{L} = \sum_{(\mathbf{h}, \mathbf{r}, \mathbf{t}) \in S} \sum_{(\mathbf{h'}, \mathbf{r}, \mathbf{t'}) \in S'} \max(0, f_{r}(h, t) + \gamma - f_{r}(h', t'))$$

Donde $S$ son las tripletas verdaderas y $S'$ son las tripletas falsas.

---

### Conclusi贸n y Aplicaciones

La elecci贸n del modelo de *embedding* (TransE, ComplEx, HolE, RotatE, etc.) depende de la estructura y la complejidad de las relaciones en el Grafo de Conocimiento. TransE ofrece simplicidad y es un excelente punto de partida, mientras que ComplEx proporciona una mayor expresividad para grafos con complejas interacciones sem谩nticas, lo que es vital en campos como la biomedicina, la b煤squeda sem谩ntica y los sistemas de recomendaci贸n.


---

Continua: [[22.1.2](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/22-1-2.md)] 

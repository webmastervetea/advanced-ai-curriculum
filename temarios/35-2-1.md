
##  Inferencia sobre Datos Cifrados: El C贸mputo Cero-Confianza

El objetivo de la **Inferencia sobre Datos Cifrados** es permitir que un servicio de *Machine Learning* (el servidor, que tiene el modelo $\mathbf{W}$) pueda realizar una predicci贸n sobre los datos de un cliente ($\mathbf{x}$) de manera que el servidor **nunca** vea $\mathbf{x}$ y el cliente **nunca** vea $\mathbf{W}$.

Esto se logra mediante t茅cnicas criptogr谩ficas avanzadas que permiten realizar operaciones matem谩ticas directamente sobre los datos cifrados.

---

### 1. Cifrado Homom贸rfico (Homomorphic Encryption, HE)

El **Cifrado Homom贸rfico (HE)** es el est谩ndar de oro y la t茅cnica m谩s rigurosa. Permite realizar c贸mputos arbitrarios en los datos cifrados.

#### A. Principio Fundamental
El cifrado homom贸rfico es un tipo de cifrado que permite realizar operaciones matem谩ticas sobre el texto cifrado ($\text{Ciphertext}$) de tal manera que, al descifrar el resultado, este es el mismo que se obtendr铆a al realizar la operaci贸n sobre el texto plano ($\text{Plaintext}$).

* **Propiedad Clave:**
    $$\text{Descifrar}(\text{Cifrar}(A) \odot \text{Cifrar}(B)) = A \odot B$$
    Donde $\odot$ es una operaci贸n (suma o multiplicaci贸n).

#### B. Tipos de Cifrado Homom贸rfico
La practicidad de HE depende de las operaciones que soporte:

1.  **Parcialmente Homom贸rfico (PHE):** Soporta solo una operaci贸n (ej. solo suma, como Paillier, o solo multiplicaci贸n).
2.  **Algo Homom贸rfico (SHE):** Soporta tanto suma como multiplicaci贸n, pero solo un n煤mero limitado de veces.
3.  **Completamente Homom贸rfico (FHE):** Soporta un n煤mero ilimitado de sumas y multiplicaciones. Esto es lo que se necesita para ejecutar una red neuronal profunda.

#### C. Implementaci贸n en *Deep Learning*
Las redes neuronales est谩n compuestas por sumas ponderadas, multiplicaciones y funciones de activaci贸n.

* **Multiplicaci贸n Ponderada:** $\sum x_i w_i$ (Suma y Multiplicaci贸n)
* **Problema de las No Linealidades:** Las funciones de activaci贸n no lineales como ReLU o *Softmax* son extremadamente dif铆ciles y costosas de aproximar con operaciones homom贸rficas (que son inherentemente lineales/polin贸micas).

* **Soluci贸n:** Los modelos de IA se entrenan con funciones de activaci贸n m谩s simples, como las **funciones polin贸micas de bajo grado**, para que puedan ser ejecutadas eficientemente por un esquema FHE.



---

### 2. C贸mputo Seguro Multipartito (Secure Multi-Party Computation, MPC)

El MPC es una t茅cnica criptogr谩fica que permite a m煤ltiples partes (el cliente y el servidor) calcular una funci贸n en com煤n sin que ninguna de ellas revele sus entradas privadas a la otra.

#### A. Principio Fundamental
El MPC descompone la funci贸n de inferencia en operaciones que son seguras de ejecutar cuando la entrada est谩 en un formato de **secreto compartido (*secret sharing*)**.

* **Mecanismo:** El cliente divide sus datos de entrada $\mathbf{x}$ en m煤ltiples partes aleatorias (acciones) y las env铆a al servidor y a otros posibles "servidores de ayuda". Ninguna parte conoce $\mathbf{x}$, pero la combinaci贸n de las acciones les permite calcular la predicci贸n.
* **Aplicaci贸n:** Ideal para escenarios donde tanto los datos de entrada del cliente como los pesos del modelo del servidor deben permanecer secretos.

#### B. Implementaci贸n en *Deep Learning*
El MPC se utiliza para ejecutar operaciones matem谩ticas de forma segura.

* **Ventaja:** Maneja mejor las no linealidades que el Cifrado Homom贸rfico puro. La no linealidad se puede resolver con protocolos de MPC optimizados (ej. Oblivious Transfer).
* **Desaf铆o:** La latencia es generalmente m谩s alta que el HE, ya que requiere m煤ltiples rondas de comunicaci贸n entre las partes.

---

### 3. Otros Enfoques Relacionados

#### A. *Federated Learning* (Aprendizaje Federado) con Privacidad
Aunque FL es para el entrenamiento, se utiliza junto con la criptograf铆a.

* **Secreto de los Datos:** Se garantiza el secreto de los datos de entrada, ya que nunca salen del dispositivo.
* **Secreto de las Actualizaciones:** Se utiliza **Cifrado Homom贸rfico** o **MPC** para agregar de forma segura las actualizaciones de gradiente del modelo enviadas por los clientes al servidor, asegurando que el servidor solo vea el promedio cifrado, no las contribuciones individuales.

#### B. *Differential Privacy* (Privacidad Diferencial)
Esta t茅cnica se enfoca en a帽adir **ruido calibrado** a los datos o a los gradientes del modelo para que la contribuci贸n de cualquier individuo sea insignificante.

* **Funci贸n:** No es un m茅todo de cifrado, sino una t茅cnica estad铆stica para garantizar la privacidad al hacer indistinguible la presencia o ausencia de un individuo en el *dataset* resultante o en el modelo.

### 4. Conclusi贸n

La Inferencia sobre Datos Cifrados, impulsada principalmente por el **Cifrado Homom贸rfico (FHE)** y el **C贸mputo Seguro Multipartito (MPC)**, es el puente entre la utilidad del *Deep Learning* y la necesidad de una privacidad robusta. Aunque la sobrecarga computacional del FHE sigue siendo un desaf铆o, los avances continuos en la optimizaci贸n de *hardware* y los nuevos esquemas criptogr谩ficos est谩n haciendo que el c贸mputo cero-confianza sea una realidad pr谩ctica en dominios sensibles como la banca, la atenci贸n m茅dica y la defensa.

---

Continua: [[36.1.1](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/36-1-1.md)] 

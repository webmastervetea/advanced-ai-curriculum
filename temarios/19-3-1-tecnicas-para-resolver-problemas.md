#  T茅cnicas de Optimizaci贸n con Restricciones (Optimizaci贸n Restringida)

Los problemas de **Optimizaci贸n Restringida** son aquellos en los que buscamos maximizar o minimizar una **funci贸n objetivo** ($f(\mathbf{x})$) sujeto a un conjunto de **restricciones** que limitan el espacio de soluciones posibles. En el mundo real, casi todos los problemas de optimizaci贸n (log铆stica, ingenier铆a, finanzas) caen en esta categor铆a, ya que las soluciones deben cumplir con limitaciones de recursos, tiempo, presupuesto o reglas f铆sicas.

El desaf铆o es encontrar el punto 贸ptimo ($\mathbf{x}^*$) que se encuentra dentro de la **regi贸n factible** definida por estas restricciones.

## 1. Clasificaci贸n de las Restricciones

Las restricciones se clasifican en funci贸n de su naturaleza matem谩tica:

* **Restricciones de Igualdad:** Limitan la soluci贸n a una superficie o curva definida por $g_i(\mathbf{x}) = 0$.
* **Restricciones de Desigualdad:** Limitan la soluci贸n a una regi贸n (o hipersuperficie) definida por $h_j(\mathbf{x}) \le 0$.



---

## 2. T茅cnicas Cl谩sicas de Optimizaci贸n Restringida

Para problemas matem谩ticos bien definidos, las t茅cnicas cl谩sicas buscan transformar el problema restringido en uno no restringido.

### A. Multiplicadores de Lagrange (Restricciones de Igualdad)

Esta es la t茅cnica fundamental para resolver problemas de optimizaci贸n sujetos solo a **restricciones de igualdad**.

* **Mecanismo:** El m茅todo introduce una nueva variable, el **multiplicador de Lagrange** ($\lambda$), por cada restricci贸n. Se construye una nueva funci贸n (*Lagrangiano*) que combina la funci贸n objetivo y las restricciones.
* **F贸rmula:** Se busca optimizar el Lagrangiano:
    $$L(\mathbf{x}, \mathbf{\lambda}) = f(\mathbf{x}) - \sum_{i} \lambda_i g_i(\mathbf{x})$$
    El punto 贸ptimo $\mathbf{x}^*$ se encuentra cuando el gradiente de $L$ con respecto a $\mathbf{x}$ y $\mathbf{\lambda}$ es cero, que corresponde a las **condiciones de Karush-Kuhn-Tucker (KKT)**.

### B. Condiciones de Karush-Kuhn-Tucker (KKT)

Las condiciones KKT son la generalizaci贸n de los multiplicadores de Lagrange para incluir tanto **restricciones de igualdad como de desigualdad**. Son condiciones necesarias (bajo ciertas suposiciones de regularidad) para que una soluci贸n sea localmente 贸ptima en un problema no lineal.

### C. M茅todos de Penalizaci贸n

En lugar de imponer las restricciones de forma estricta, estos m茅todos las incorporan directamente en la funci贸n objetivo como un **t茅rmino de penalizaci贸n**.

* **Mecanismo:** Si una soluci贸n candidata viola una restricci贸n, se le aplica una penalizaci贸n alta a su *fitness* (valor de la funci贸n objetivo).
    $$f_{\text{penalizado}}(\mathbf{x}) = f(\mathbf{x}) + P(\mathbf{x})$$
    Donde $P(\mathbf{x})$ es una funci贸n que es cero si las restricciones se cumplen, y aumenta cuadr谩ticamente si se violan.

---

## 3. T茅cnicas Metaheur铆sticas para Problemas Complejos

Para problemas de optimizaci贸n combinatoria o con funciones objetivo de "caja negra" (no derivables), los m茅todos metaheur铆sticos son m谩s efectivos.

### A. Algoritmos Gen茅ticos (GA) y Manejo de Restricciones

Los GA deben adaptarse para operar dentro de un espacio restringido:

1.  **T茅rmino de Penalizaci贸n:** El enfoque m谩s com煤n es usar la **funci贸n de penalizaci贸n** (descrita arriba). Las soluciones infactibles tienen un *fitness* muy bajo y son eliminadas por la selecci贸n natural.
2.  **Representaci贸n de la Soluci贸n (Codificaci贸n):** La estructura del cromosoma se dise帽a para que sea **imposible generar soluciones infactibles**.
    * *Ejemplo:* En un problema de ruteo con capacidad de camiones, la codificaci贸n del GA se asegura de que la suma de las demandas nunca exceda la capacidad.
3.  **Reparaci贸n:** Despu茅s de la operaci贸n de **cruce** o **mutaci贸n**, si la nueva soluci贸n viola una restricci贸n, se aplica un operador de **reparaci贸n** que la ajusta a la frontera de la regi贸n factible m谩s cercana.

### B. Optimizaci贸n por Colonia de Hormigas (ACO)

ACO es naturalmente adecuado para algunos problemas restringidos, como el **Problema del Viajante (TSP)**, donde la restricci贸n es que cada ciudad debe visitarse una sola vez.

* **Mecanismo:** La estructura del algoritmo impone la restricci贸n. El algoritmo de construcci贸n de rutas de la hormiga solo permite elegir nodos que a煤n no han sido visitados, garantizando la factibilidad de la ruta generada.

---

## 4. Programaci贸n Lineal y Entera (La Base Estricta)

Para problemas donde la funci贸n objetivo y las restricciones son lineales, se utilizan m茅todos de optimizaci贸n estricta:

* **Programaci贸n Lineal (LP):** Si $f(\mathbf{x})$ y todas las restricciones son lineales, el m茅todo del **S铆mplex** garantiza encontrar el 贸ptimo global en la frontera de la regi贸n factible.
* **Programaci贸n Entera (IP):** Cuando las variables $\mathbf{x}$ deben ser n煤meros enteros (comprar un n煤mero entero de m谩quinas, asignar una tarea a un individuo), se utilizan algoritmos de **Ramificaci贸n y Acotamiento (*Branch and Bound*)** para resolver la complejidad adicional.

El enfoque m谩s adecuado para la optimizaci贸n restringida siempre depende de la naturaleza del problema: **m茅todos anal铆ticos** para problemas bien comportados, y **metaheur铆sticas** para problemas combinatorios o de alta complejidad.


---

Continua: [[20-1-1]()] 

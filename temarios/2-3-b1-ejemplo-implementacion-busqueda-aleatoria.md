## 游 Ejemplo de Implementaci칩n: B칰squeda Aleatoria en una Red Neuronal

Imaginemos que estamos construyendo una red neuronal de clasificaci칩n simple y queremos optimizar tres hiperpar치metros clave.

### 1. Definici칩n del Espacio de B칰squeda

Primero, definimos el rango de valores (el espacio de b칰squeda) para los hiperpar치metros que consideramos m치s influyentes:

| Hiperpar치metro | Tipo | Espacio de B칰squeda (Rango de Valores) |
| :--- | :--- | :--- |
| **Tasa de Aprendizaje** (*Learning Rate*) | Real (logar칤tmico) | De $10^{-4}$ a $10^{-1}$ (ej. 0.0001 a 0.1) |
| **N칰mero de Capas Ocultas** | Entero discreto | $\{1, 2, 3\}$ |
| **Tama침o del Lote** (*Batch Size*) | Entero discreto | $\{16, 32, 64, 128\}$ |

### 2. Metodolog칤a de B칰squeda Aleatoria

En lugar de probar todas las $3 \times 4 = 12$ combinaciones posibles (si la Tasa de Aprendizaje fuera tambi칠n un conjunto peque침o de valores discretos), la B칰squeda Aleatoria nos permite muestrear combinaciones de manera m치s eficiente.

**Procedimiento:**

1.  **Iteraciones ($N$):** Decidimos que haremos $N=10$ pruebas (iteraciones) en total.
2.  **Muestreo Aleatorio:** En cada iteraci칩n, se selecciona un valor al azar para cada hiperpar치metro dentro de su rango:
    * **Tasa de Aprendizaje:** Se suele muestrear en una escala logar칤tmica (por ejemplo, $\log_{10}(\text{LR})$ se muestrea uniformemente), ya que las diferencias entre $10^{-4}$ y $10^{-3}$ son tan cr칤ticas como entre $10^{-2}$ y $10^{-1}$.
    * **N칰mero de Capas y Tama침o del Lote:** Se muestrean uniformemente de su conjunto discreto.
3.  **Entrenamiento y Evaluaci칩n:** Por cada combinaci칩n muestreada:
    * Se configura y entrena el modelo.
    * Se eval칰a su rendimiento (ej. precisi칩n) en el **conjunto de validaci칩n**.

### 3. Ejemplo de Ejecuci칩n (Tabla de Resultados)

La tabla muestra un posible resultado de 5 de las 10 iteraciones, junto con la precisi칩n obtenida en el conjunto de validaci칩n:

| Iteraci칩n | Tasa de Aprendizaje | Capas Ocultas | Tama침o del Lote | Precisi칩n en Validaci칩n |
| :---: | :---: | :---: | :---: | :---: |
| 1 | 0.005 | 2 | 64 | 85.1% |
| 2 | 0.08 | 1 | 128 | 78.9% |
| 3 | **0.0009** | **3** | **32** | **88.5%** |
| 4 | 0.02 | 2 | 16 | 84.0% |
| 5 | 0.001 | 3 | 128 | 87.2% |

### 4. Selecci칩n del Mejor Modelo

Al finalizar las 10 iteraciones, revisamos la tabla y seleccionamos la combinaci칩n de hiperpar치metros que arroj칩 la mejor m칠trica:

* En este ejemplo, la **Iteraci칩n 3** ofrece el mejor rendimiento con una Precisi칩n de Validaci칩n del **88.5%**.
* Los hiperpar치metros 칩ptimos (dentro de este espacio de b칰squeda y estas 10 pruebas) son: $\text{Tasa de Aprendizaje}=0.0009$, $\text{Capas}=3$, $\text{Lote}=32$.

### 5. Prueba Final

Solo despu칠s de seleccionar esta mejor combinaci칩n, se entrena el modelo **una 칰ltima vez** con el conjunto de entrenamiento completo (o la combinaci칩n de entrenamiento + validaci칩n) y se eval칰a su rendimiento en el **conjunto de prueba** (el que nunca se ha visto). Este resultado final es la m칠trica de rendimiento que se reporta.

---

### 쯇or qu칠 la B칰squeda Aleatoria es Mejor que la B칰squeda en Rejilla?

La ventaja crucial de la B칰squeda Aleatoria se muestra cuando solo un subconjunto de hiperpar치metros es realmente importante.

* **En la B칰squeda en Rejilla:** Si se prueba la Tasa de Aprendizaje con 5 valores y el Tama침o del Lote con 5 valores, y el Tama침o del Lote es irrelevante, se dedican 5 pruebas a variaciones in칰tiles en el Lote por cada valor de la Tasa de Aprendizaje.
* **En la B칰squeda Aleatoria:** Se tiene una mayor probabilidad de muestrear valores significativamente diferentes para el hiperpar치metro verdaderamente importante (ej. la Tasa de Aprendizaje) en las $N$ iteraciones, explorando de manera m치s efectiva la dimensi칩n cr칤tica.



La B칰squeda Aleatoria maximiza la posibilidad de probar valores 칰nicos y potencialmente 칩ptimos a lo largo de cada dimensi칩n de hiperpar치metro, siendo m치s eficiente para descubrir combinaciones ganadoras.



---

Continua: [[3-1](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/3-1-autoencoders-variacionales-vae.md)] 

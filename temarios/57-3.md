

##  Teor铆a de la Mente (ToM): Modelado de Creencias e Intenciones

La ToM es esencial para cualquier agente que deba cooperar, competir o interactuar socialmente. Implica construir y mantener un **Modelo del Otro (MoA)**.

### 1. Los Niveles de la Teor铆a de la Mente en IA

La ToM en IA se divide en varios niveles de complejidad, reflejando la capacidad del agente para anidar creencias:

| Nivel de ToM | Descripci贸n | Ejemplo |
| :--- | :--- | :--- |
| **Nivel 0** | El agente es reactivo, no tiene ToM. | El robot solo se mueve cuando se le ordena. |
| **Nivel 1 (Creencias Simples)** | El agente infiere la creencia simple de otro agente. | "El robot cree que la caja est谩 en la mesa." |
| **Nivel 2 (Creencias de Creencias)** | El agente infiere la creencia del otro agente sobre *su* propia creencia. | "El robot cree que **yo creo** que la caja est谩 en la mesa." (Doble anidaci贸n) |
| **Nivel 3+** | Niveles anidados superiores (exponencialmente m谩s complejos). | Cruciales para el sarcasmo, el enga帽o y la diplomacia. |

### 2. Modelado de Creencias con Redes Bayesianas

Los **Sistemas de Creencias** (como se discuti贸 previamente) son la base matem谩tica para la ToM.

* **Mecanismo:** El agente de IA mantiene dos conjuntos de creencias (o **Modelos del Mundo**):
    1.  **Creencias Propias ($K_{\text{agente}}$):** El conocimiento real del agente sobre el estado del mundo.
    2.  **Creencias Atribuidas ($K_{\text{otro}}$):** El modelo del agente sobre **lo que el otro agente cree** que es el estado del mundo.
* **Actualizaci贸n:** El agente utiliza las observaciones del comportamiento del otro (acciones, verbalizaciones) como **evidencia** para actualizar $K_{\text{otro}}$ a trav茅s de la Inferencia Bayesiana.

### 3. Inferencia de Intenciones y Deseos

Inferir lo que alguien *quiere* hacer es m谩s complejo que inferir lo que *sabe*.

#### A. Modelado de la Racionalidad Limitada (*Bounded Rationality*)
Los agentes humanos no son perfectamente racionales; a menudo toman atajos.

* **Mecanismo:** La IA asume que el otro agente intentar谩 **maximizar la utilidad** para **sus propias metas y deseos** (sus variables internas). La IA utiliza esta suposici贸n para **ingenier铆a inversa** (razonamiento abductivo) el deseo subyacente.
* **Ejemplo:** Si un agente de ayuda observa que un humano toma una ruta m谩s larga y peligrosa, la IA infiere (abduce) que el humano debe tener un **deseo oculto** (ej. "el deseo de recoger un objeto en esa ruta") que supera el deseo de seguridad.

### 4. La ToM en Modelos de Lenguaje Grande (LLMs)

Los LLMs pre-entrenados demuestran una ToM sorprendentemente eficaz, aunque se debate si es una simulaci贸n superficial o una capacidad emergente.

#### A. Razonamiento Contrafactual y Escenarios
Los LLMs pueden generar narrativas que requieren ToM de Nivel 2.

* **Mecanismo:** El LLM recibe una historia (ej. el cl谩sico **Test de Sally-Anne**) donde la creencia de un personaje ($A$) es falsa respecto a la realidad del agente ($B$). Se le pide al LLM que prediga el comportamiento de $A$.
* **Funci贸n:** El LLM predice correctamente que $A$ actuar谩 bas谩ndose en su **falsa creencia** ($K_A \neq K_{\text{agente}}$). Esto sugiere que el modelo ha aprendido el patr贸n sint谩ctico y sem谩ntico de la ToM.

#### B. *Prompting* de Rol y Colaboraci贸n
Para la colaboraci贸n, el LLM debe modelar las capacidades y el conocimiento del otro agente.

* **Mecanismo:** En un *prompt* de planificaci贸n de tareas, se le indica al LLM que piense como un planificador que interact煤a con un socio humano. El *prompt* puede incluir: "El humano es bueno en el dise帽o, pero lento en la ejecuci贸n."
* **Funci贸n:** El LLM **asigna tareas** bas谩ndose en este modelo expl铆cito del otro, demostrando una ToM rudimentaria de las **capacidades** y la **divisi贸n del conocimiento** del compa帽ero.

### 5. Aplicaciones Cruciales: Colaboraci贸n y Rob贸tica

1.  **Rob贸tica Colaborativa (Cobots):** Un robot de f谩brica necesita predecir la intenci贸n de la mano de un trabajador para ralentizar, detenerse o ajustar su trayectoria de manera segura.
2.  **Agentes de Negociaci贸n:** La IA debe modelar los **puntos de reserva** y las **utilidades** del oponente para encontrar una soluci贸n que maximice el valor percibido por el otro (ganar-ganar), no solo la ganancia ego铆sta.
3.  **Veh铆culos Aut贸nomos:** Un coche aut贸nomo infiere la intenci贸n de un peat贸n (ej. si est谩 distra铆do o va a cruzar) bas谩ndose en su velocidad y orientaci贸n de la mirada, y ajusta su velocidad para optimizar la seguridad y el flujo del tr谩fico.

---

### Conclusi贸n

La **Teor铆a de la Mente (ToM)** es la clave para la interacci贸n social sofisticada en la IA. Al utilizar **Redes Bayesianas** para modelar las creencias anidadas de otros agentes y aplicando principios de **Racionalidad Limitada** para inferir deseos e intenciones, los agentes de IA pueden pasar de ser reactivos a ser **colaboradores proactivos**. Esta capacidad es esencial para cualquier aplicaci贸n de IA que implique una interacci贸n compleja y din谩mica con humanos u otros agentes inteligentes.

---

Continua: [[58-1](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/58-1.md)] 

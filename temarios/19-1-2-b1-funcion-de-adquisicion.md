#  La Funci贸n de Adquisici贸n: Mejora Esperada (EI)

La **Mejora Esperada (*Expected Improvement*, EI)** es la funci贸n de adquisici贸n m谩s popular y eficaz utilizada en la **Optimizaci贸n Bayesiana (BO)**. Su prop贸sito es guiar el proceso de b煤squeda, determinando **cu谩l es el siguiente punto del espacio de hiperpar谩metros ($\mathbf{x}_{\text{next}}$) que se debe evaluar** en la funci贸n objetivo (el error de validaci贸n del modelo).

La fuerza de la EI radica en que cuantifica directamente, en t茅rminos de valor de la funci贸n objetivo, la **mejora potencial** que se puede obtener al probar un punto, incorporando la incertidumbre del **Proceso Gaussiano (GP)**.

## 1. El Principio de la Mejora

La **Mejora (*Improvement*, $I(\mathbf{x})$)** es una m茅trica simple que mide cu谩nto mejor es un posible resultado ($f(\mathbf{x})$) en un punto $\mathbf{x}$ que el mejor valor de funci贸n objetivo encontrado hasta ahora ($f_{\text{best}}$). Dado que la BO busca la minimizaci贸n del error, la mejora se define como:

$$I(\mathbf{x}) = \max(0, f_{\text{best}} - f(\mathbf{x}))$$

Donde $f(\mathbf{x})$ es el valor de la funci贸n objetivo en el punto $\mathbf{x}$. Si el valor predicho es peor (m谩s grande) que $f_{\text{best}}$, la mejora es cero. Si es mejor (m谩s peque帽o), la mejora es la diferencia.

## 2. El Paso a la Mejora Esperada (EI)

Dado que el GP nos proporciona una **distribuci贸n probabil铆stica** sobre $f(\mathbf{x})$ (y no un valor 煤nico), no podemos simplemente usar la *Mejora* ($I(\mathbf{x})$). En su lugar, utilizamos la **Mejora Esperada (EI)**, que es el valor esperado de $I(\mathbf{x})$ sobre la distribuci贸n de predicci贸n del GP.

La distribuci贸n de predicci贸n del GP en el punto $\mathbf{x}$ es una normal: $f(\mathbf{x}) \sim \mathcal{N}(\mu(\mathbf{x}), \sigma^2(\mathbf{x}))$.

La f贸rmula de la Mejora Esperada es:

$$EI(\mathbf{x}) = \sigma(\mathbf{x}) \cdot (\phi(Z) + Z \cdot \Phi(Z))$$

Donde:
* $Z = \frac{f_{\text{best}} - \mu(\mathbf{x})}{\sigma(\mathbf{x})}$
* $\mu(\mathbf{x})$ y $\sigma(\mathbf{x})$ son la media y la desviaci贸n est谩ndar de la predicci贸n del GP en $\mathbf{x}$.
* $\phi(Z)$ es la funci贸n de densidad de probabilidad est谩ndar normal.
* $\Phi(Z)$ es la funci贸n de distribuci贸n acumulativa est谩ndar normal.

## 3. El Equilibrio Estrat茅gico: Exploraci贸n vs. Explotaci贸n

La belleza de la f贸rmula de EI es que incorpora la incertidumbre ($\sigma(\mathbf{x})$) y la cercan铆a al 贸ptimo conocido ($\mu(\mathbf{x})$) de manera equilibrada, lo que se traduce en una toma de decisiones inteligente:

### A. Explotaci贸n (Cuando $\sigma(\mathbf{x})$ es Baja)

Si la incertidumbre ($\sigma(\mathbf{x})$) es baja, el valor de $EI(\mathbf{x})$ estar谩 dominado por el t茅rmino $\mu(\mathbf{x})$.

* El EI ser谩 alto cerca de los puntos donde la **predicci贸n de la media ($\mu$) es mucho mejor que $f_{\text{best}}$**.
* El algoritmo se enfoca en **explotar** regiones donde el GP est谩 seguro de que la funci贸n objetivo tiene un valor excelente.

### B. Exploraci贸n (Cuando $\sigma(\mathbf{x})$ es Alta)

Si la incertidumbre ($\sigma(\mathbf{x})$) es alta, pero la predicci贸n de la media ($\mu$) no es necesariamente la mejor, el gran valor de $\sigma(\mathbf{x})$ puede mantener el $EI(\mathbf{x})$ alto.

* Esto alienta al algoritmo a **explorar** regiones que a煤n no se han muestreado. Incluso si la media predicha no es fant谩stica, la alta incertidumbre implica que **podr铆a haber un pico de mejora** oculto all铆.



## 4. Un Ligerio Sesgo: La Mejora Esperada con Ruido

En la pr谩ctica, la f贸rmula se modifica ligeramente introduciendo un t茅rmino $\epsilon$ (peque帽o y positivo) para dar un sesgo sutil hacia la exploraci贸n:

$$I_{\epsilon}(\mathbf{x}) = \max(0, f_{\text{best}} - f(\mathbf{x}) - \epsilon)$$

Este t茅rmino $\epsilon$ asegura que el algoritmo siempre tenga un incentivo para **explorar nuevos puntos**, en lugar de simplemente volver a probar un punto cercano al 贸ptimo actual, incluso si el GP predice que no habr谩 una mejora masiva.

## 5. Conclusi贸n

La **Mejora Esperada (EI)** proporciona un criterio robusto para la toma de decisiones secuencial en la Optimizaci贸n Bayesiana. Al calcular la ganancia esperada de la evaluaci贸n de un punto, el EI permite que la BO supere la ineficiencia de la b煤squeda ciega, convergiendo r谩pidamente al 贸ptimo global de la funci贸n de error de validaci贸n con el menor n煤mero posible de costosos entrenamientos de modelos.


---

Continua: [[19-1-2-b2](https://github.com/webmastervetea/advanced-ai-curriculum/blob/main/temarios/19-1-2-b2-funcion-adquisicion-mejora-esperada.md)] 
